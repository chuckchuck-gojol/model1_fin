{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 1 - 기능 1, 2, 3에 대해 처리 가능한 모델1 작성 (2)\n",
    "#### ver 3.3\n",
    "#### 최종 수정일 : 20-05-25\n",
    "#### 이화여대 컴퓨터공학전공 졸업 프로젝트\n",
    "#### 위잉위잉(척척고졸)-권지현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "## 2. 모델링\n",
    "### 2.1 데이터 구성\n",
    "\n",
    "> [변경사항]\n",
    "\n",
    "* * *\n",
    "> [기존과 동일]\n",
    "- model_1.npz 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3497, 193), (3497, 1))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 알림, 차량 엔진, 차량 경적, 지하철 트리거 순\n",
    "sound_data = np.load('model_1.npz')\n",
    "X_train = sound_data['X']\n",
    "y_train = sound_data['y']\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3497, 193), (3497, 1))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "## 2. 모델링\n",
    "### 2.2 모델 학습\n",
    "\n",
    "> [변경사항]\n",
    "- lstm 사용\n",
    "- 이전 모델의 경우 파라미터 조정에 초점을 두었으나 ver 3.5에서는 layer 구성에 초점을 두어 진행\n",
    "* * *\n",
    "> [기존과 동일]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential() # Sequeatial Model\n",
    "model.add(LSTM(20, input_shape=(193, 1))) # (timestep, feature)\n",
    "model.add(Dense(1)) # output = 1\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.values\n",
    "X_train = X_train.reshape(X_train.shape[0], 193, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 1.5702\n",
      "Epoch 2/100\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 1.2128\n",
      "Epoch 3/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.1071\n",
      "Epoch 4/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0286\n",
      "Epoch 5/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9506\n",
      "Epoch 6/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9092\n",
      "Epoch 7/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8712\n",
      "Epoch 8/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8550\n",
      "Epoch 9/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8209\n",
      "Epoch 10/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8035\n",
      "Epoch 11/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7542\n",
      "Epoch 12/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7121\n",
      "Epoch 13/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.6532\n",
      "Epoch 14/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.6324\n",
      "Epoch 15/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.6297\n",
      "Epoch 16/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.6075\n",
      "Epoch 17/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.5727\n",
      "Epoch 18/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.5649\n",
      "Epoch 19/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.5562\n",
      "Epoch 20/100\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.5619\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26139696508>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          batch_size=30, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "## 2. 모델링\n",
    "### 2.3 모델 저장\n",
    "\n",
    "> [변경사항]\n",
    "- pkl, json, pb, tflite로 저장\n",
    "* * *\n",
    "> [기존과 동일]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/pkl/model_1.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 pkl로 저장하기\n",
    "import joblib\n",
    "joblib.dump(model, 'model/pkl/model_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 json으로 저장하기\n",
    "model_1 = model.to_json()\n",
    "# model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 h5로 저장하기\n",
    "from keras.models import load_model\n",
    "model.save('model/h5/model_1')\n",
    "model.save('model/h5/model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/pb/assets\n"
     ]
    }
   ],
   "source": [
    "# 모델 pb로 저장하기\n",
    "model = keras.models.load_model('model/h5/model_1', compile=False)\n",
    "model.save('model/pb/',save_format=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "See console for info.\n2020-05-26 22:18:59.778839: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2020-05-26 22:18:59.779224: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2020-05-26 22:19:03.763709: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2020-05-26 22:19:03.765597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\n2020-05-26 22:19:03.794741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0\ncoreClock: 1.2415GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 14.92GiB/s\n2020-05-26 22:19:03.796081: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2020-05-26 22:19:03.797514: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found\n2020-05-26 22:19:03.799765: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n2020-05-26 22:19:03.801535: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n2020-05-26 22:19:03.802907: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\n2020-05-26 22:19:03.804317: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found\n2020-05-26 22:19:03.805416: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found\n2020-05-26 22:19:03.805764: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n2020-05-26 22:19:03.867351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n2020-05-26 22:19:03.867677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n2020-05-26 22:19:03.867869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n2020-05-26 22:19:03.877726: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\n2020-05-26 22:19:03.878028: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-26 22:19:03.878318: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\n2020-05-26 22:19:03.878592: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-26 22:19:03.878852: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\n2020-05-26 22:19:03.879101: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-26 22:19:03.879333: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-26 22:19:03.879555: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\n2020-05-26 22:19:03.880314: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 20 operators, 56 arrays (0 quantized)\n2020-05-26 22:19:03.880826: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 20 operators, 56 arrays (0 quantized)\n2020-05-26 22:19:03.881723: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 7 operators, 36 arrays (0 quantized)\n2020-05-26 22:19:03.882237: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 7 operators, 36 arrays (0 quantized)\n2020-05-26 22:19:03.882845: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 7 operators, 36 arrays (0 quantized)\n2020-05-26 22:19:03.883327: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 7 operators, 36 arrays (0 quantized)\n2020-05-26 22:19:03.883924: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 832 bytes, theoretical optimal value: 832 bytes.\n2020-05-26 22:19:03.884350: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 1817\n2020-05-26 22:19:03.884896: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListFromTensor is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.885276: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListReserve is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.885644: W tensorflow/lite/toco/tflite/operator.cc:2024] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.885993: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListStack is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.886426: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListFromTensor is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.886799: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListReserve is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.887169: W tensorflow/lite/toco/tflite/operator.cc:2024] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.887517: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListStack is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.887930: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\nTraceback (most recent call last):\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\jih02\\AppData\\Local\\Continuum\\anaconda3\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-1f26f02537b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m converter.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS,\n\u001b[0;32m      5\u001b[0m                                      tf.lite.OpsSet.SELECT_TF_OPS]\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtfilte_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/tflite/model_1.tflite'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mftlite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m         **converter_kwargs)\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[0;32m    458\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    201\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;31m# Must manually cleanup files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConverterError\u001b[0m: See console for info.\n2020-05-26 22:18:59.778839: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2020-05-26 22:18:59.779224: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2020-05-26 22:19:03.763709: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2020-05-26 22:19:03.765597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\n2020-05-26 22:19:03.794741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0\ncoreClock: 1.2415GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 14.92GiB/s\n2020-05-26 22:19:03.796081: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2020-05-26 22:19:03.797514: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found\n2020-05-26 22:19:03.799765: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n2020-05-26 22:19:03.801535: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n2020-05-26 22:19:03.802907: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\n2020-05-26 22:19:03.804317: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found\n2020-05-26 22:19:03.805416: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found\n2020-05-26 22:19:03.805764: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n2020-05-26 22:19:03.867351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n2020-05-26 22:19:03.867677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n2020-05-26 22:19:03.867869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n2020-05-26 22:19:03.877726: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\n2020-05-26 22:19:03.878028: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-26 22:19:03.878318: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\n2020-05-26 22:19:03.878592: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-26 22:19:03.878852: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\n2020-05-26 22:19:03.879101: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-26 22:19:03.879333: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-26 22:19:03.879555: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\n2020-05-26 22:19:03.880314: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 20 operators, 56 arrays (0 quantized)\n2020-05-26 22:19:03.880826: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 20 operators, 56 arrays (0 quantized)\n2020-05-26 22:19:03.881723: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 7 operators, 36 arrays (0 quantized)\n2020-05-26 22:19:03.882237: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 7 operators, 36 arrays (0 quantized)\n2020-05-26 22:19:03.882845: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 7 operators, 36 arrays (0 quantized)\n2020-05-26 22:19:03.883327: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 7 operators, 36 arrays (0 quantized)\n2020-05-26 22:19:03.883924: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 832 bytes, theoretical optimal value: 832 bytes.\n2020-05-26 22:19:03.884350: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 1817\n2020-05-26 22:19:03.884896: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListFromTensor is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.885276: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListReserve is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.885644: W tensorflow/lite/toco/tflite/operator.cc:2024] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.885993: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListStack is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.886426: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListFromTensor is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.886799: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListReserve is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.887169: W tensorflow/lite/toco/tflite/operator.cc:2024] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.887517: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListStack is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-26 22:19:03.887930: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\nTraceback (most recent call last):\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\jih02\\AppData\\Local\\Continuum\\anaconda3\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\n\n"
     ]
    }
   ],
   "source": [
    "#모델 tflite 로 저장하기\n",
    "saved_model_dir='model/pb/'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                     tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tfilte_mode=converter.convert()\n",
    "open('model/tflite/model_1.tflite','wb').write(ftlite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
